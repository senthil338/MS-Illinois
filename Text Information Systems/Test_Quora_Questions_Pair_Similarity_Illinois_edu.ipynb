{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import keras.layers as layers\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "np.random.seed(10)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "# enabling the pretrained model for trainig our custom model using tensorflow hub\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
    "embed = hub.Module(module_url)\n",
    "\n",
    "# creating a method for embedding and will using method for every input layer \n",
    "def UniversalEmbedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 512)          0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 512)          0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1024)         0           lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 200)          205000      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 200)          0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 200)          800         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 200)          40200       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 200)          0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 200)          800         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 200)          40200       batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 200)          0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 200)          800         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 200)          40200       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 200)          0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 200)          800         dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 2)            402         batch_normalization_12[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 329,202\n",
      "Trainable params: 327,602\n",
      "Non-trainable params: 1,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    DROPOUT = 0.1\n",
    "    # Taking the question1 as input and ceating a embedding for each question before feed it to neural network\n",
    "    q1 = layers.Input(shape=(1,), dtype=tf.string)\n",
    "    embedding_q1 = layers.Lambda(UniversalEmbedding, output_shape=(512,))(q1)\n",
    "    # Taking the question2 and doing the same thing mentioned above, using the lambda function\n",
    "    q2 = layers.Input(shape=(1,), dtype=tf.string)\n",
    "    embedding_q2 = layers.Lambda(UniversalEmbedding, output_shape=(512,))(q2)\n",
    "\n",
    "    # Concatenating the both input layer\n",
    "    merged = layers.concatenate([embedding_q1, embedding_q2])\n",
    "    merged = layers.Dense(200, activation='relu')(merged)\n",
    "    merged = layers.Dropout(DROPOUT)(merged)\n",
    "\n",
    "    # Normalizing the input layer,applying dense and dropout  layer for fully connected model and to avoid overfitting \n",
    "    merged = layers.BatchNormalization()(merged)\n",
    "    merged = layers.Dense(200, activation='relu')(merged)\n",
    "    merged = layers.Dropout(DROPOUT)(merged)\n",
    "\n",
    "    merged = layers.BatchNormalization()(merged)\n",
    "    merged = layers.Dense(200, activation='relu')(merged)\n",
    "    merged = layers.Dropout(DROPOUT)(merged)\n",
    "\n",
    "    merged = layers.BatchNormalization()(merged)\n",
    "    merged = layers.Dense(200, activation='relu')(merged)\n",
    "    merged = layers.Dropout(DROPOUT)(merged)\n",
    "\n",
    "    # Using the Sigmoid as the activation function and binary crossentropy for binary classifcation as 0 or 1\n",
    "    merged = layers.BatchNormalization()(merged)\n",
    "    pred = layers.Dense(2, activation='sigmoid')(merged)\n",
    "    model = Model(inputs=[q1,q2], outputs=pred)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while executing below code 2nd time onwards it display a \"session closed\" warning message , please do not consider that, \n",
    "# still it produce the expected result as we already tranied the model and stored it in local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Question 1 here -->Is it possible to uninstall the integrated Siri software on the iPhone 4S?\n",
      "Type Question 2 here -->Is Siri a part of the iPhone 4S?\n",
      "Question 1 --> Is it possible to uninstall the integrated Siri software on the iPhone 4S?\n",
      "Question 2 --> Is Siri a part of the iPhone 4S?\n",
      "----FINAL RESULT----\n",
      "****Questions are not Similar****\n"
     ]
    }
   ],
   "source": [
    "  q1 = input(\"Type Question 1 here -->\")\n",
    "  q2 = input(\"Type Question 2 here -->\")\n",
    "  print(\"Question 1 --> \" + q1) \n",
    "  print(\"Question 2 --> \" + q2)\n",
    "  q1 = np.array([[q1],[q1]])\n",
    "  q2 = np.array([[q2],[q2]])\n",
    "\n",
    "\n",
    "# Using the same tensorflow session for embedding the test string\n",
    "  with tf.Session() as session:\n",
    "    K.set_session(tf.Session())\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    # Loading the save weights\n",
    "    model.load_weights('quora-model-10-0.84.hdf5')  \n",
    "    # Predicting the similarity between the two input questions \n",
    "    predicts = model.predict([q1, q2], verbose=0)\n",
    "    predict_logits = predicts.argmax(axis=1)\n",
    "    print(\"----FINAL RESULT----\")\n",
    "    if(predict_logits[0] == 1):\n",
    "      print(\"****Questions are Similar****\")\n",
    "    else:\n",
    "      print(\"****Questions are not Similar****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nQ1 = \"How does weight loss transformation affect your personality ?\", Q2 = \"Did your weight loss transformation affect your personality ?\"\\nQ1 = \"Can excessive amounts of Vitamin C cause me to have a miscarriage?\",Q2 = \"How can Vitamin C cause a miscarriage?\"\\nQ1 = \"Which are the best engineering fields?\",Q2 = \"What is the best field of engineering?\"\\nQ1 = \"How do you get deleted Instagram chats?\", Q2 = \"How can I view deleted Instagram dms?\\nQ1 = \"Is it possible to uninstall the integrated Siri software on the iPhone 4S?\", Q2= \"Is Siri a part of the iPhone 4S?\"\\nQ1 = \"What are T-rays?\", Q2 = \"What is an X-ray?\"\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Q1 = \"How does weight loss transformation affect your personality ?\", Q2 = \"Did your weight loss transformation affect your personality ?\"\n",
    "Q1 = \"Can excessive amounts of Vitamin C cause me to have a miscarriage?\",Q2 = \"How can Vitamin C cause a miscarriage?\"\n",
    "Q1 = \"Which are the best engineering fields?\",Q2 = \"What is the best field of engineering?\"\n",
    "Q1 = \"How do you get deleted Instagram chats?\", Q2 = \"How can I view deleted Instagram dms?\n",
    "Q1 = \"Is it possible to uninstall the integrated Siri software on the iPhone 4S?\", Q2= \"Is Siri a part of the iPhone 4S?\"\n",
    "Q1 = \"What are T-rays?\", Q2 = \"What is an X-ray?\"\n",
    "\n",
    "\n",
    "Q1 = Can excessive amounts of Vitamin C cause me to have a miscarriage?\",Q2 = \"How can Vitamin C cause a miscarriage?\" 1\n",
    "Q1 =\"Which are the best engineering fields?\",Q2 = \"What is the best field of engineering?\",\"1\"\n",
    "Q1 =\"How do you get deleted Instagram chats?\",Q2 = \"How can I view deleted Instagram dms?\",\"1\"\n",
    "Q1 =\"What if I hired two private eyes and ordered them to follow each other?\",Q2 = \"Would I be able to hire two private investigators and then get them to follow each other?\",\"1\"\n",
    "Q1 =\"What is the best combination of courses I can take up along with CA to enhance my career?\",Q2 = \"What courses must be taken along with CA course?\",\"1\"\n",
    "Q1 =\"What are some must watch TV shows before you die?\",Q2 = \"Are there any must watch TV shows?\",\"1\"\n",
    "Q1 =\"I am ugly and fat, how to lose weight?\",Q2 = \"How do I actually lose weight?\",\"1\"\n",
    "Q1 =\"How can I clear the bank exams after degree?\",Q2 = \"How can I clear bank exams after my graduation? Which books to refer?\",\"1\"\n",
    "Q1 =\"Setting aside religious teachings, what do you consider as possible evidence for life after death?\",Q2 = \"Is there any tangible evidence for life after death?\",\"1\"\n",
    "\n",
    "\n",
    "\n",
    "Q1 =\"Is it possible to uninstall the integrated Siri software on the iPhone 4S?\",Q2 = \"Is Siri a part of the iPhone 4S?\",\"0\"\n",
    "Q1 =\"Is Uber safe to use if you're a female riding solo?\",Q2 = \"Is it safe to use Uber in Dubai?\",\"0\"\n",
    "Q1 =\"What is the nearest airport to Daytona Beach, and how do this cities tourist attractions compare to Billing's?\",Q2 = \"What is the nearest airport to Daytona Beach, and how do this cities tourist attractions compare to Orlando's?\",\"0\"\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
